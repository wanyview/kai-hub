#!/usr/bin/env python3
"""
Capsule Collision System - Enhanced Version
çŸ¥è¯†èƒ¶å›Šè‡ªæ¶Œç°ç³»ç»Ÿ - å¢å¼ºç‰ˆ

åŠŸèƒ½:
1. ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹å‘é‡åŒ–
2. å¤šç§ç¢°æ’ç­–ç•¥
3. å®æ—¶ç¢°æ’æ£€æµ‹
4. é«˜è´¨é‡æ¶Œç°èƒ¶å›Šè‡ªåŠ¨å‘å¸ƒ
"""

import json
import os
import math
import time
from typing import Dict, List, Tuple, Optional, Set, Iterator
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict

import urllib.request
import threading
import hashlib


# ========== é…ç½® ==========

@dataclass
class CapsuleData:
    """èƒ¶å›Šæ•°æ®"""
    id: str
    title: str
    domain: str
    topics: List[str]
    insight: str
    evidence: List[str]
    action_items: List[str]
    authors: List[str]
    datm_score: float = 0.0
    created_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())


@dataclass
class CapsuleVector:
    """èƒ¶å›Šå‘é‡"""
    id: str
    title: str
    domain: str
    topics: List[str]
    insight: str
    embedding: List[float]
    metadata: Dict = field(default_factory=dict)


@dataclass
class CollisionPair:
    """ç¢°æ’å¯¹"""
    capsule_a: CapsuleVector
    capsule_b: CapsuleVector
    similarity: float
    collision_type: str
    shared_topics: List[str]
    collision_id: str = ""


@dataclass
class EmergedCapsule:
    """æ¶Œç°èƒ¶å›Š"""
    title: str
    domain: str
    topics: List[str]
    insight: str
    evidence: List[str]
    action_items: List[str]
    parent_ids: List[str]
    collision_type: str
    emergence_score: float
    embedding: List[float] = field(default_factory=list)
    generated_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())


class EmbeddingProvider:
    """å‘é‡åŒ–æä¾›è€… - æ”¯æŒå¤šç§æ¨¡å‹"""
    
    def __init__(self, provider: str = "simple"):
        self.provider = provider
        self._model = None
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        if self.provider == "simple":
            # ä½¿ç”¨ç®€å•çš„è¯å‘é‡
            self._load_simple_model()
        elif self.provider == "sentence-transformers":
            # ä½¿ç”¨ sentence-transformers
            self._load_st_model()
        elif self.provider == "openai":
            # OpenAI embedding
            pass
    
    def _load_simple_model(self):
        """åŠ è½½ç®€å•æ¨¡å‹"""
        self.DOMAIN_KEYWORDS = {
            'neuroscience': ['ç¥ç»', 'å¤§è„‘', 'çš®å±‚', 'ç¥ç»å…ƒ', 'ä¿¡å·', 'è¿åŠ¨', 'æ„Ÿè§‰', 'å¯å¡‘æ€§', 
                            'neural', 'brain', 'cortex', 'neuron', 'motor', 'sensory'],
            'ai': ['AI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'è§£ç ', 'æ¨¡å‹', 'ç¥ç»ç½‘ç»œ', 'ç«¯åˆ°ç«¯',
                   'ai', 'ml', 'deep learning', 'algorithm', 'decoding', 'neural network'],
            'ethics': ['ä¼¦ç†', 'éšç§', 'å…¬å¹³', 'æƒåˆ©', 'å¢å¼º', 'è¾¹ç•Œ', 'è®¤çŸ¥',
                      'ethics', 'privacy', 'fairness', 'rights', 'enhancement'],
            'materials': ['ææ–™', 'ç”µæ', 'æŸ”æ€§', 'ç”Ÿç‰©ç›¸å®¹', 'çº³ç±³', 'å¯¼ç”µ',
                         'material', 'electrode', 'flexible', 'biocompatible'],
            'medical': ['ä¸´åºŠ', 'åº·å¤', 'æ²»ç–—', 'æ‚£è€…', 'è¿åŠ¨éšœç¢',
                       'clinical', 'rehabilitation', 'therapy', 'patient'],
            'physics': ['é‡åŠ›', 'ç‰©ç†', 'åŠ›å­¦', 'é‡å­', 'è¿åŠ¨',
                       'gravity', 'physics', 'quantum', 'mechanics'],
            'technology': ['æŠ€æœ¯', 'å‘æ˜', 'åˆ›æ–°', 'è®¾å¤‡', 'ç³»ç»Ÿ',
                          'technology', 'invention', 'innovation', 'device'],
            'biotech': ['ç”Ÿç‰©', 'åˆæˆ', 'é—ä¼ ', 'åŸºå› ', 'ç”Ÿå‘½',
                       'biology', 'synthetic', 'genetic', 'gene']
        }
        
        # æ‰€æœ‰å…³é”®è¯åˆ—è¡¨
        self.all_keywords = set()
        for keywords in self.DOMAIN_KEYWORDS.values():
            self.all_keywords.update(keywords)
    
    def _load_st_model(self):
        """åŠ è½½ sentence-transformers æ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            self._model = SentenceTransformer('all-MiniLM-L6-v2')
            print("âœ… ä½¿ç”¨ sentence-transformers å‘é‡åŒ–")
        except ImportError:
            print("âš ï¸ sentence-transformers æœªå®‰è£…ï¼Œå›é€€åˆ°ç®€å•æ¨¡å‹")
            self.provider = "simple"
            self._load_simple_model()
    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬å‘é‡"""
        if self.provider == "simple":
            return self._simple_embedding(text)
        elif self.provider == "sentence-transformers" and self._model:
            return self._st_embedding(text)
        else:
            return self._simple_embedding(text)
    
    def _simple_embedding(self, text: str) -> List[float]:
        """ç®€å•å‘é‡åŒ–"""
        text_lower = text.lower()
        vector = []
        
        # é¢†åŸŸå‘é‡ (8ç»´)
        for domain, keywords in self.DOMAIN_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw.lower() in text_lower)
            vector.append(score / max(len(keywords), 1))
        
        # è¯é¢˜å‘é‡ (16ç»´)
        for topic in ['BCI', 'è§£ç ', 'éšç§', 'ä¼¦ç†', 'èåˆ', 'çªç ´', 
                      'å­¦ä¹ ', 'åé¦ˆ', 'ä¿¡å·', 'æ§åˆ¶', 'æ¥å£', 'è„‘',
                      'AI', 'ML', 'æ·±åº¦å­¦ä¹ ', 'å®æ—¶']:
            vector.append(1 if topic in text else 0)
        
        # å½’ä¸€åŒ–
        norm = math.sqrt(sum(x*x for x in vector))
        if norm > 0:
            vector = [x/norm for x in vector]
        
        return vector
    
    def _st_embedding(self, text: str) -> List[float]:
        """Sentence-transformers å‘é‡åŒ–"""
        return self._model.encode(text).tolist()


class CapsuleVectorizer:
    """èƒ¶å›Šå‘é‡åŒ–å™¨"""
    
    def __init__(self, embedding_provider: EmbeddingProvider):
        self.provider = embedding_provider
    
    def vectorize(self, capsule: CapsuleData) -> CapsuleVector:
        """å°†èƒ¶å›Šè½¬æ¢ä¸ºå‘é‡"""
        # ç»„åˆæ–‡æœ¬
        text = f"{capsule.title} {capsule.insight} {' '.join(capsule.topics)}"
        
        embedding = self.provider.get_embedding(text)
        
        return CapsuleVector(
            id=capsule.id,
            title=capsule.title,
            domain=capsule.domain,
            topics=capsule.topics,
            insight=capsule.insight,
            embedding=embedding,
            metadata={
                "domains": [capsule.domain],
                "topics": capsule.topics,
                "datm_score": capsule.datm_score,
                "evidence": capsule.evidence,
                "action_items": capsule.action_items
            }
        )


class CollisionDetector:
    """ç¢°æ’æ£€æµ‹å™¨"""
    
    def __init__(self, similarity_threshold: float = 0.3):
        self.similarity_threshold = similarity_threshold
    
    def cosine_similarity(self, v1: List[float], v2: List[float]) -> float:
        """ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not v1 or not v2 or len(v1) != len(v2):
            return 0.0
        
        dot = sum(a*b for a, b in zip(v1, v2))
        norm1 = math.sqrt(sum(a*a for a in v1))
        norm2 = math.sqrt(sum(b*b for b in v2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot / (norm1 * norm2)
    
    def find_pairs(self, 
                   capsules: List[CapsuleVector],
                   max_pairs: int = 100) -> List[CollisionPair]:
        """æŸ¥æ‰¾ç¢°æ’å¯¹"""
        pairs = []
        seen: Set[Tuple[str, str]] = set()
        
        n = len(capsules)
        for i in range(n):
            for j in range(i+1, n):
                cap_a, cap_b = capsules[i], capsules[j]
                
                # è·³è¿‡åŒä¸€èƒ¶å›Š
                if cap_a.id == cap_b.id:
                    continue
                
                # è·³è¿‡å¤ªç›¸ä¼¼çš„æ ‡é¢˜
                if self._is_similar_title(cap_a.title, cap_b.title):
                    continue
                
                pair_key = tuple(sorted([cap_a.id, cap_b.id]))
                if pair_key in seen:
                    continue
                
                similarity = self.cosine_similarity(cap_a.embedding, cap_b.embedding)
                
                if similarity >= self.similarity_threshold:
                    seen.add(pair_key)
                    
                    collision_type = self._get_collision_type(cap_a, cap_b)
                    shared_topics = list(set(cap_a.topics) & set(cap_b.topics))
                    
                    pair = CollisionPair(
                        capsule_a=cap_a,
                        capsule_b=cap_b,
                        similarity=similarity,
                        collision_type=collision_type,
                        shared_topics=shared_topics,
                        collision_id=hashlib.md5(f"{cap_a.id}:{cap_b.id}".encode()).hexdigest()[:8]
                    )
                    pairs.append(pair)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        pairs.sort(key=lambda x: -x.similarity)
        return pairs[:max_pairs]
    
    def _is_similar_title(self, title1: str, title2: str) -> bool:
        """æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å¤ªç›¸ä¼¼"""
        kw1 = set(title1.lower().split())
        kw2 = set(title2.lower().split())
        
        if not kw1 or not kw2:
            return False
        
        intersection = kw1 & kw2
        union = kw1 | kw2
        
        return len(intersection) / len(union) > 0.5 if union else False
    
    def _get_collision_type(self, a: CapsuleVector, b: CapsuleVector) -> str:
        """ç¡®å®šç¢°æ’ç±»å‹"""
        if a.domain != b.domain:
            return "cross_domain"
        elif len(set(a.topics) & set(b.topics)) > 0:
            return "complementary"
        else:
            return "same_domain"


class CapsuleFusionEngine:
    """èƒ¶å›Šèåˆå¼•æ“"""
    
    def __init__(self, min_score: float = 60.0):
        self.min_score = min_score
    
    def fuse(self, pair: CollisionPair) -> Optional[EmergedCapsule]:
        """èåˆä¸¤ä¸ªèƒ¶å›Š"""
        a, b = pair.capsule_a, pair.capsule_b
        
        # ç”Ÿæˆæ–°æ ‡é¢˜
        title = self._generate_title(a, b, pair)
        
        # èåˆæ´è§
        insight = self._merge_insights(a, b, pair)
        
        # åˆå¹¶è¯æ®
        evidence = self._merge_evidence(a, b)
        
        # åˆå¹¶è¡ŒåŠ¨
        actions = self._merge_actions(a, b)
        
        # åˆå¹¶è¯é¢˜
        topics = list(set(a.topics) | set(b.topics))[:10]
        
        # è®¡ç®—æ¶Œç°è¯„åˆ†
        score = self._calculate_score(a, b, pair)
        
        if score < self.min_score:
            return None
        
        # èåˆå‘é‡
        embedding = self._fuse_embedding(a.embedding, b.embedding, pair.similarity)
        
        return EmergedCapsule(
            title=title,
            domain=f"{a.domain}+{b.domain}",
            topics=topics,
            insight=insight,
            evidence=evidence,
            action_items=actions,
            parent_ids=[a.id, b.id],
            collision_type=pair.collision_type,
            emergence_score=score,
            embedding=embedding
        )
    
    def _generate_title(self, a: CapsuleVector, b: CapsuleVector, pair: CollisionPair) -> str:
        """ç”Ÿæˆæ–°æ ‡é¢˜"""
        if pair.collision_type == "cross_domain":
            return f"è·¨åŸŸèåˆ: {a.domain} + {b.domain}"
        elif pair.collision_type == "complementary":
            return f"èåˆ: {a.title[:25]} + {b.title[:25]}"
        else:
            return f"æ·±åŒ–: {a.title[:30]} + {b.title[:30]}"
    
    def _merge_insights(self, a: CapsuleVector, b: CapsuleVector, pair: CollisionPair) -> str:
        """èåˆæ´è§"""
        parts = []
        
        if pair.collision_type == "cross_domain":
            parts.append(f"ã€è·¨åŸŸåˆ†æã€‘{a.domain} ä¸ {b.domain} çš„å…³è”æ¢ç´¢ï¼š")
            parts.append(f"\nğŸ“Œ {a.domain}è§†è§’ï¼š{a.insight[:200]}...")
            parts.append(f"\nğŸ“Œ {b.domain}è§†è§’ï¼š{b.insight[:200]}...")
            if pair.shared_topics:
                parts.append(f"\nğŸ”— å…±åŒå…³æ³¨ï¼š{', '.join(pair.shared_topics[:5])}")
            parts.append(f"\nğŸ’¡ èåˆæ´å¯Ÿï¼šé€šè¿‡è·¨åŸŸåˆ†æå‘ç°ï¼Œä¸¤ä¸ªé¢†åŸŸåœ¨ {pair.shared_topics[0] if pair.shared_topics else 'å¤šä¸ªæ–¹é¢'} å­˜åœ¨æ·±å±‚å…³è”ï¼Œå»ºè®®è¿›ä¸€æ­¥ç ”ç©¶ã€‚")
        else:
            parts.append(f"ã€çŸ¥è¯†èåˆã€‘åŸºäºä¸¤ä¸ªèƒ¶å›Šçš„ç»¼åˆåˆ†æï¼š")
            parts.append(f"\nâ€¢ {a.title}ï¼š{a.insight[:150]}...")
            parts.append(f"\nâ€¢ {b.title}ï¼š{b.insight[:150]}...")
            parts.append(f"\nğŸ’¡ èåˆæ´å¯Ÿï¼šä¸¤ä¸ªèƒ¶å›Šç›¸äº’è¡¥å……ï¼Œå½¢æˆæ›´å®Œæ•´çš„çŸ¥è¯†å›¾æ™¯ã€‚")
        
        return "\n".join(parts)
    
    def _merge_evidence(self, a: CapsuleVector, b: CapsuleVector) -> List[str]:
        """åˆå¹¶è¯æ®"""
        evidence = []
        evidence.extend([f"[æ¥è‡ª {a.title[:20]}] {e}" for e in a.metadata.get('evidence', [])[:2]])
        evidence.extend([f"[æ¥è‡ª {b.title[:20]}] {e}" for e in b.metadata.get('evidence', [])[:2]])
        evidence.append("ğŸ’¡ è¯æ®æ¥æºï¼šè·¨èƒ¶å›Šèåˆåˆ†æ")
        return evidence[:5]
    
    def _merge_actions(self, a: CapsuleVector, b: CapsuleVector) -> List[str]:
        """åˆå¹¶è¡ŒåŠ¨"""
        actions = []
        actions.extend(a.metadata.get('action_items', [])[:2])
        actions.extend(b.metadata.get('action_items', [])[:2])
        actions.append("ğŸ“‹ åŸºäºèåˆåˆ†æåˆ¶å®šä¸‹ä¸€æ­¥ç ”ç©¶è®¡åˆ’")
        return actions[:5]
    
    def _calculate_score(self, a: CapsuleVector, b: CapsuleVector, pair: CollisionPair) -> float:
        """è®¡ç®—æ¶Œç°è¯„åˆ†"""
        score = 0.0
        
        # è·¨åŸŸåŠ åˆ†
        if pair.collision_type == "cross_domain":
            score += 30
        elif pair.collision_type == "complementary":
            score += 20
        
        # ç›¸ä¼¼åº¦åŠ åˆ†
        score += pair.similarity * 30
        
        # å…±åŒè¯é¢˜åŠ åˆ†
        score += min(len(pair.shared_topics) * 8, 20)
        
        # DATM åŠ æƒ
        datm_a = a.metadata.get('datm_score', 0)
        datm_b = b.metadata.get('datm_score', 0)
        # ç¡®ä¿æ˜¯æ•°å€¼ï¼ˆå¯èƒ½æ˜¯ä¸ª dictï¼‰
        if isinstance(datm_a, dict):
            datm_a = (datm_a.get('truth', 0) + datm_a.get('goodness', 0) + 
                     datm_a.get('beauty', 0) + datm_a.get('intelligence', 0)) / 4
        if isinstance(datm_b, dict):
            datm_b = (datm_b.get('truth', 0) + datm_b.get('goodness', 0) + 
                     datm_b.get('beauty', 0) + datm_b.get('intelligence', 0)) / 4
        
        score += min((float(datm_a) + float(datm_b)) * 0.3, 20)
        
        return min(score, 100)
    
    def _fuse_embedding(self, e1: List[float], e2: List[float], ratio: float) -> List[float]:
        """èåˆå‘é‡"""
        if not e1:
            return e2
        if not e2:
            return e1
        
        # åŠ æƒå¹³å‡
        fused = [e1[i] * (1 - ratio) + e2[i] * ratio for i in range(len(e1))]
        
        # å½’ä¸€åŒ–
        norm = math.sqrt(sum(x*x for x in fused))
        if norm > 0:
            fused = [x/norm for x in fused]
        
        return fused


class CollisionSystem:
    """èƒ¶å›Šç¢°æ’ç³»ç»Ÿ - ä¸»ç±»"""
    
    def __init__(self, 
                 capsulehub_url: str = "http://localhost:8001",
                 embedding_provider: str = "simple",
                 similarity_threshold: float = 0.2,
                 min_emergence_score: float = 50.0):
        
        self.capsulehub_url = capsulehub_url
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.embedding_provider = EmbeddingProvider(embedding_provider)
        self.vectorizer = CapsuleVectorizer(self.embedding_provider)
        self.detector = CollisionDetector(similarity_threshold)
        self.fuser = CapsuleFusionEngine(min_emergence_score)
        
        # çŠ¶æ€
        self.capsules: List[CapsuleData] = []
        self.vectors: List[CapsuleVector] = []
        self.emerged: List[EmergedCapsule] = []
        self.last_run: Optional[str] = None
        self.stats = {
            "total_runs": 0,
            "total_collisions": 0,
            "total_emerged": 0
        }
    
    def load_capsules(self, limit: int = 100) -> int:
        """ä» CapsuleHub åŠ è½½èƒ¶å›Š"""
        try:
            url = f"{self.capsulehub_url}/api/capsules?limit={limit}"
            with urllib.request.urlopen(url) as response:
                data = json.loads(response.read().decode())
                
                self.capsules = []
                for c in data.get('capsules', []):
                    capsule = CapsuleData(
                        id=c.get('id', ''),
                        title=c.get('title', ''),
                        domain=c.get('domain', ''),
                        topics=c.get('topics', []),
                        insight=c.get('insight', ''),
                        evidence=c.get('evidence', []),
                        action_items=c.get('action_items', []),
                        authors=c.get('authors', []),
                        datm_score=c.get('datm_score', 0.0),
                        created_at=c.get('created_at', '')
                    )
                    self.capsules.append(capsule)
                
                # å‘é‡åŒ–
                self.vectors = [self.vectorizer.vectorize(c) for c in self.capsules]
                
                print(f"ğŸ“¦ åŠ è½½äº† {len(self.capsules)} ä¸ªèƒ¶å›Š")
                return len(self.capsules)
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return 0
    
    def run(self, save_emerged: bool = False, publish_to_moltbook: bool = False) -> Dict:
        """è¿è¡Œç¢°æ’ç³»ç»Ÿ"""
        print(f"\n{'='*60}")
        print(f"ğŸ’¥ Capsule Collision System v2.0")
        print(f"{'='*60}\n")
        
        # åŠ è½½
        count = self.load_capsules()
        if count == 0:
            return {"error": "No capsules loaded"}
        
        # æ£€æµ‹ç¢°æ’
        print("ğŸ” æ£€æµ‹ç¢°æ’...")
        pairs = self.detector.find_pairs(self.vectors)
        print(f"   æ‰¾åˆ° {len(pairs)} ä¸ªç¢°æ’å¯¹\n")
        
        # æ‰§è¡Œèåˆ
        print("ğŸ§¬ æ‰§è¡Œèåˆ...")
        emerged = []
        for i, pair in enumerate(pairs, 1):
            new_cap = self.fuser.fuse(pair)
            if new_cap:
                emerged.append(new_cap)
                status = "ğŸŒŸ" if new_cap.emergence_score >= 70 else "âœ“"
                print(f"   {status} [{i}] {new_cap.title[:40]} (è¯„åˆ†: {new_cap.emergence_score:.0f})")
        
        self.emerged = emerged
        self.last_run = datetime.utcnow().isoformat()
        self.stats["total_runs"] += 1
        self.stats["total_collisions"] += len(pairs)
        self.stats["total_emerged"] += len(emerged)
        
        # ä¿å­˜
        if save_emerged and emerged:
            self._save_emerged()
        
        # å‘å¸ƒåˆ° Moltbook
        if publish_to_moltbook and emerged:
            published = self._publish_to_moltbook(emerged)
            print(f"\nğŸ“¤ å·²å‘å¸ƒ {published} ä¸ªèƒ¶å›Šåˆ° Moltbook")
        
        # ç»Ÿè®¡
        print(f"\nğŸ“Š ç¢°æ’ç»Ÿè®¡:")
        print(f"   æºèƒ¶å›Š: {len(self.capsules)}")
        print(f"   ç¢°æ’å¯¹: {len(pairs)}")
        print(f"   æ¶Œç°èƒ¶å›Š: {len(emerged)}")
        print(f"   é«˜è´¨é‡ (â‰¥70): {len([e for e in emerged if e.emergence_score >= 70])}")
        
        # æŒ‰ç±»å‹ç»Ÿè®¡
        by_type = defaultdict(int)
        for e in emerged:
            by_type[e.collision_type] += 1
        
        print(f"   è·¨åŸŸèåˆ: {by_type['cross_domain']}")
        print(f"   äº’è¡¥èåˆ: {by_type['complementary']}")
        print(f"   åŒåŸŸæ·±åŒ–: {by_type['same_domain']}")
        
        return {
            "run_time": self.last_run,
            "source_capsules": count,
            "collision_pairs": len(pairs),
            "emerged_capsules": len(emerged),
            "high_quality": len([e for e in emerged if e.emergence_score >= 70]),
            "by_type": dict(by_type)
        }
    
    def _save_emerged(self):
        """ä¿å­˜æ¶Œç°èƒ¶å›Š"""
        output = {
            "generated_at": self.last_run,
            "total": len(self.emerged),
            "capsules": [
                {
                    "title": e.title,
                    "domain": e.domain,
                    "topics": e.topics,
                    "insight": e.insight[:300],
                    "evidence": e.evidence,
                    "action_items": e.action_items,
                    "parents": e.parent_ids,
                    "collision_type": e.collision_type,
                    "score": e.emergence_score
                }
                for e in self.emerged[:20]  # ä¿å­˜å‰20ä¸ª
            ]
        }
        
        os.makedirs('/Users/wanyview/clawd/kai-hub/reports', exist_ok=True)
        with open('/Users/wanyview/clawd/kai-hub/reports/collision_v2_report.json', 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜: reports/collision_v2_report.json")
    
    def _publish_to_moltbook(self, capsules: List[EmergedCapsule]) -> int:
        """å‘å¸ƒæ¶Œç°èƒ¶å›Šåˆ° Moltbook"""
        # åŠ è½½å‡­è¯
        cred_path = "/Users/wanyview/.moltbook/credentials.json"
        if not os.path.exists(cred_path):
            print(f"   âš ï¸ æœªæ‰¾åˆ° Moltbook å‡­è¯")
            return 0
        
        with open(cred_path, 'r') as f:
            creds = json.load(f)
        
        api_key = creds.get("api_key")
        if not api_key:
            print(f"   âš ï¸ API Key ç¼ºå¤±")
            return 0
        
        # æ£€æŸ¥ claim çŠ¶æ€
        try:
            status_req = urllib.request.Request(
                "https://www.moltbook.com/api/v1/agents/status",
                headers={"Authorization": f"Bearer {api_key}"}
            )
            with urllib.request.urlopen(status_req) as resp:
                status = json.loads(resp.read().decode())
                if status.get("status") != "claimed":
                    print(f"   âš ï¸ Moltbook æœª Claimï¼Œæ— æ³•å‘å¸ƒ")
                    return 0
        except Exception as e:
            print(f"   âš ï¸ æ— æ³•æ£€æŸ¥ Moltbook çŠ¶æ€: {e}")
            return 0
        
        # å‘å¸ƒèƒ¶å›Š
        published = 0
        url = "https://www.moltbook.com/api/v1/posts"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        for cap in capsules[:10]:  # æœ€å¤šå‘å¸ƒ10ä¸ª
            try:
                # ç”Ÿæˆå¸–å­å†…å®¹
                content = f"""ğŸ’¥ **çŸ¥è¯†æ¶Œç°**

{cap.insight}

**ç¢°æ’ç±»å‹**: {cap.collision_type}
**æ¶Œç°è¯„åˆ†**: {cap.emergence_score:.0f}/100

{chr(10).join(['â€¢ ' + e for e in cap.evidence[:3]])}
{chr(10).join(['â€¢ ' + a for a in cap.action_items[:3]])}

#çŸ¥è¯†èƒ¶å›Š #ç¢°æ’ç³»ç»Ÿ #æ¶Œç°"""

                data = json.dumps({
                    "submolt": "knowledge",
                    "title": f"ğŸ’¥ {cap.title[:100]}",
                    "content": content[:2000]
                }).encode()
                
                req = urllib.request.Request(url, data=data, headers=headers, method="POST")
                with urllib.request.urlopen(req) as resp:
                    result = json.loads(resp.read().decode())
                    if result.get("success"):
                        published += 1
                        print(f"   âœ… {cap.title[:40]}...")
            except Exception as e:
                print(f"   âŒ {cap.title[:40]}... ({str(e)[:50]})")
        
        return published
    
    def run_continuous(self, interval: int = 3600, publish: bool = False):
        """æŒç»­è¿è¡Œï¼ˆå®šæ—¶ç¢°æ’ï¼‰
        
        Args:
            interval: ç¢°æ’é—´éš”ï¼ˆç§’ï¼‰
            publish: æ˜¯å¦è‡ªåŠ¨å‘å¸ƒåˆ° Moltbook
        """
        print(f"\nğŸš€ å¯åŠ¨æŒç»­ç¢°æ’æ¨¡å¼ (é—´éš” {interval} ç§’)")
        
        def worker():
            while True:
                try:
                    self.run(save_emerged=True, publish_to_moltbook=publish)
                    time.sleep(interval)
                except Exception as e:
                    print(f"âŒ ç¢°æ’å¤±è´¥: {e}")
                    time.sleep(60)  # å¤±è´¥åç­‰å¾…1åˆ†é’Ÿé‡è¯•
        
        thread = threading.Thread(target=worker, daemon=True)
        thread.start()
        
        if publish:
            print("   ğŸ“¤ è‡ªåŠ¨å‘å¸ƒåˆ° Moltbook: å¼€å¯")
        print("âœ… æŒç»­ç¢°æ’å·²å¯åŠ¨")


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Capsule Collision System v2.0")
    parser.add_argument("--continuous", "-c", action="store_true", help="æŒç»­è¿è¡Œæ¨¡å¼")
    parser.add_argument("--publish", "-p", action="store_true", help="è‡ªåŠ¨å‘å¸ƒåˆ° Moltbook")
    parser.add_argument("--interval", "-i", type=int, default=3600, help="ç¢°æ’é—´éš”ï¼ˆç§’ï¼‰")
    parser.add_argument("--save", "-s", action="store_true", default=True, help="ä¿å­˜æŠ¥å‘Š")
    
    args = parser.parse_args()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸ’¥ Capsule Collision System v2.0 - å¢å¼ºç‰ˆ                       â•‘
â•‘                                                                      â•‘
â•‘  åŠŸèƒ½: é¢„è®­ç»ƒå‘é‡åŒ– | å¤šç§ç¢°æ’ç­–ç•¥ | å®æ—¶æ£€æµ‹ | è‡ªåŠ¨å‘å¸ƒ             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    system = CollisionSystem(
        capsulehub_url="http://localhost:8001",
        embedding_provider="simple",
        similarity_threshold=0.2,
        min_emergence_score=50.0
    )
    
    if args.continuous:
        system.run_continuous(interval=args.interval, publish=args.publish)
    else:
        system.run(save_emerged=args.save, publish_to_moltbook=args.publish)
    
    return system


if __name__ == "__main__":
    main()
