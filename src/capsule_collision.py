#!/usr/bin/env python3
"""
Capsule Collision Engine - çŸ¥è¯†èƒ¶å›Šè‡ªæ¶Œç°ç³»ç»Ÿ

è®©çŸ¥è¯†èƒ¶å›Šä¹‹é—´ç›´æ¥ç¢°æ’ï¼Œåœ¨è¯­ä¹‰ç©ºé—´ä¸­äº§ç”Ÿæ–°çš„çŸ¥è¯†ç«èŠ±ï¼
"""

import json
import os
import math
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime
from collections import defaultdict
import urllib.request


# ========== é…ç½® ==========

@dataclass
class CapsuleVector:
    """èƒ¶å›Šå‘é‡"""
    id: str
    title: str
    domain: str
    topics: List[str]
    insight: str
    evidence: List[str]
    action_items: List[str]
    embedding: List[float] = field(default_factory=list)
    vector_id: str = ""


@dataclass  
class CollisionPair:
    """ç¢°æ’å¯¹"""
    capsule_a: CapsuleVector
    capsule_b: CapsuleVector
    similarity: float
    collision_type: str  # "cross_domain", "same_domain", "complementary"
    shared_topics: List[str]


@dataclass
class EmergedCapsule:
    """æ¶Œç°çš„æ–°èƒ¶å›Š"""
    title: str
    domain: str
    topics: List[str]
    insight: str
    evidence: List[str]
    action_items: List[str]
    parent_capsules: List[str]
    collision_type: str
    emergence_score: float
    generated_at: str = field(default_factory=lambda: datetime.utcnow().isoformat())


class CapsuleVectorizer:
    """èƒ¶å›Šå‘é‡åŒ–å™¨"""
    
    # é¢†åŸŸå…³é”®è¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…å¯ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼‰
    DOMAIN_KEYWORDS = {
        'neuroscience': ['ç¥ç»', 'å¤§è„‘', 'çš®å±‚', 'ç¥ç»å…ƒ', 'ä¿¡å·', 'è¿åŠ¨', 'æ„Ÿè§‰', 'å¯å¡‘æ€§'],
        'ai': ['AI', 'æœºå™¨å­¦ä¹ ', 'æ·±åº¦å­¦ä¹ ', 'ç®—æ³•', 'è§£ç ', 'æ¨¡å‹', 'ç¥ç»ç½‘ç»œ', 'ç«¯åˆ°ç«¯'],
        'ethics': ['ä¼¦ç†', 'éšç§', 'å…¬å¹³', 'æƒåˆ©', 'å¢å¼º', 'è¾¹ç•Œ', 'è®¤çŸ¥'],
        'materials': ['ææ–™', 'ç”µæ', 'æŸ”æ€§', 'ç”Ÿç‰©ç›¸å®¹', 'çº³ç±³', 'å¯¼ç”µ'],
        'medical': ['ä¸´åºŠ', 'åº·å¤', 'æ²»ç–—', 'æ‚£è€…', 'è¿åŠ¨éšœç¢'],
        'physics': ['é‡åŠ›', 'ç‰©ç†', 'åŠ›å­¦', 'é‡å­', 'è¿åŠ¨'],
        'technology': ['æŠ€æœ¯', 'å‘æ˜', 'åˆ›æ–°', 'è®¾å¤‡', 'ç³»ç»Ÿ'],
        'biotech': ['ç”Ÿç‰©', 'åˆæˆ', 'é—ä¼ ', 'åŸºå› ', 'ç”Ÿå‘½']
    }
    
    def vectorize(self, capsule: Dict) -> CapsuleVector:
        """å°†èƒ¶å›Šè½¬æ¢ä¸ºå‘é‡"""
        text = f"{capsule.get('title', '')} {capsule.get('insight', '')} {' '.join(capsule.get('topics', []))}"
        
        # ç®€åŒ–ç‰ˆå‘é‡åŒ–ï¼šåŸºäºè¯é¢‘çš„å‘é‡
        embedding = self._text_to_vector(text)
        
        return CapsuleVector(
            id=capsule.get('id', ''),
            title=capsule.get('title', ''),
            domain=capsule.get('domain', ''),
            topics=capsule.get('topics', []),
            insight=capsule.get('insight', ''),
            evidence=capsule.get('evidence', []),
            action_items=capsule.get('action_items', []),
            embedding=embedding,
            vector_id=f"vec_{capsule.get('id', '')}"
        )
    
    def _text_to_vector(self, text: str) -> List[float]:
        """æ–‡æœ¬è½¬å‘é‡ï¼ˆç®€åŒ–ç‰ˆ TF-IDFï¼‰"""
        words = set(text.lower().split())
        vector = []
        
        for domain, keywords in self.DOMAIN_KEYWORDS.items():
            score = sum(1 for kw in keywords if any(w in text.lower() for w in kw.split()))
            vector.append(score / max(len(keywords), 1))
        
        # æ·»åŠ è¯é¢˜å‘é‡
        for topic in ['BCI', 'è§£ç ', 'éšç§', 'ä¼¦ç†', 'èåˆ', 'çªç ´']:
            vector.append(1 if topic in text else 0)
        
        # L2 å½’ä¸€åŒ–
        norm = math.sqrt(sum(x*x for x in vector))
        if norm > 0:
            vector = [x/norm for x in vector]
        
        return vector


class CapsuleCollisionEngine:
    """èƒ¶å›Šç¢°æ’å¼•æ“"""
    
    def __init__(self, capsulehub_url: str = "http://localhost:8001"):
        self.capsulehub_url = capsulehub_url
        self.vectorizer = CapsuleVectorizer()
        self.capsules: List[CapsuleVector] = []
        self.emerged_capsules: List[EmergedCapsule] = []
    
    def load_capsules(self, limit: int = 100) -> int:
        """ä» CapsuleHub åŠ è½½èƒ¶å›Š"""
        try:
            url = f"{self.capsulehub_url}/api/capsules?limit={limit}"
            with urllib.request.urlopen(url) as response:
                data = json.loads(response.read().decode())
                
                self.capsules = []
                for c in data.get('capsules', []):
                    vector = self.vectorizer.vectorize(c)
                    self.capsules.append(vector)
                
                print(f"ğŸ“¦ åŠ è½½äº† {len(self.capsules)} ä¸ªèƒ¶å›Š")
                return len(self.capsules)
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            return 0
    
    def cosine_similarity(self, v1: List[float], v2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not v1 or not v2 or len(v1) != len(v2):
            return 0.0
        
        dot = sum(a*b for a, b in zip(v1, v2))
        norm1 = math.sqrt(sum(a*a for a in v1))
        norm2 = math.sqrt(sum(b*b for b in v2))
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot / (norm1 * norm2)
    
    def find_collision_pairs(self, 
                            similarity_threshold: float = 0.3,
                            max_pairs: int = 50) -> List[CollisionPair]:
        """æŸ¥æ‰¾å¯èƒ½çš„ç¢°æ’å¯¹"""
        pairs = []
        seen: Set[Tuple[str, str]] = set()
        
        for i, cap_a in enumerate(self.capsules):
            for j, cap_b in enumerate(self.capsules[i+1:], i+1):
                # é¿å…é‡å¤ï¼ˆåŒä¸€ä¸ªèƒ¶å›Šï¼‰
                if cap_a.id == cap_b.id:
                    continue
                
                # é¿å…æ ‡é¢˜å¤ªç›¸ä¼¼ï¼ˆå»é‡ï¼‰
                if self._is_similar_title(cap_a.title, cap_b.title):
                    continue
                
                pair_key = tuple(sorted([cap_a.id, cap_b.id]))
                if pair_key in seen:
                    continue
                
                similarity = self.cosine_similarity(cap_a.embedding, cap_b.embedding)
                
                if similarity >= similarity_threshold:
                    seen.add(pair_key)
                    
                    # ç¡®å®šç¢°æ’ç±»å‹
                    collision_type = self._get_collision_type(cap_a, cap_b)
                    
                    # æŸ¥æ‰¾å…±åŒè¯é¢˜
                    shared_topics = list(set(cap_a.topics) & set(cap_b.topics))
                    
                    pair = CollisionPair(
                        capsule_a=cap_a,
                        capsule_b=cap_b,
                        similarity=similarity,
                        collision_type=collision_type,
                        shared_topics=shared_topics
                    )
                    pairs.append(pair)
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œä¿ç•™å‰ max_pairs
        pairs.sort(key=lambda x: -x.similarity)
        pairs = pairs[:max_pairs]
        
        print(f"ğŸ’¥ æ‰¾åˆ° {len(pairs)} ä¸ªæœ‰æ•ˆç¢°æ’å¯¹ (å»é‡å)")
        return pairs
    
    def _is_similar_title(self, title1: str, title2: str) -> bool:
        """æ£€æŸ¥æ ‡é¢˜æ˜¯å¦å¤ªç›¸ä¼¼ï¼ˆç”¨äºå»é‡ï¼‰"""
        # æå–å…³é”®è¯
        kw1 = set(title1.lower().split())
        kw2 = set(title2.lower().split())
        
        if not kw1 or not kw2:
            return False
        
        # è®¡ç®—äº¤é›†
        intersection = kw1 & kw2
        union = kw1 | kw2
        
        # å¦‚æœäº¤é›†/å¹¶é›† > 0.5ï¼Œè®¤ä¸ºå¤ªç›¸ä¼¼
        return len(intersection) / len(union) > 0.5
    
    def _get_collision_type(self, cap_a: CapsuleVector, cap_b: CapsuleVector) -> str:
        """ç¡®å®šç¢°æ’ç±»å‹"""
        if cap_a.domain != cap_b.domain:
            return "cross_domain"  # è·¨åŸŸç¢°æ’
        elif len(self._find_shared_topics(cap_a, cap_b)) > 0:
            return "complementary"  # äº’è¡¥ç¢°æ’
        else:
            return "same_domain"  # åŒåŸŸç¢°æ’
    
    def _find_shared_topics(self, cap_a: CapsuleVector, cap_b: CapsuleVector) -> Set[str]:
        """æŸ¥æ‰¾å…±åŒè¯é¢˜"""
        return set(cap_a.topics) & set(cap_b.topics)
    
    def collide(self, pair: CollisionPair) -> Optional[EmergedCapsule]:
        """æ‰§è¡Œèƒ¶å›Šç¢°æ’ï¼Œç”Ÿæˆæ–°èƒ¶å›Š"""
        a = pair.capsule_a
        b = pair.capsule_b
        
        # ç”Ÿæˆæ–°æ ‡é¢˜
        if pair.collision_type == "cross_domain":
            title = f"è·¨åŸŸèåˆ: {a.domain} + {b.domain}"
        else:
            title = f"çŸ¥è¯†èåˆ: {a.title[:20]} + {b.title[:20]}"
        
        # èåˆæ´è§
        insight = self._merge_insights(a, b, pair)
        
        # äº¤å‰éªŒè¯è¯æ®
        evidence = self._merge_evidence(a, b)
        
        # ç»“åˆè¡ŒåŠ¨å»ºè®®
        action_items = self._merge_actions(a, b)
        
        # åˆå¹¶è¯é¢˜
        topics = list(set(a.topics) | set(b.topics))[:10]
        
        # è®¡ç®—æ¶Œç°è¯„åˆ†
        emergence_score = self._calculate_emergence_score(a, b, pair)
        
        # è´¨é‡æ£€æŸ¥
        if emergence_score < 40:  # é˜ˆå€¼
            return None
        
        return EmergedCapsule(
            title=title,
            domain=f"{a.domain}+{b.domain}",
            topics=topics,
            insight=insight,
            evidence=evidence,
            action_items=action_items,
            parent_capsules=[a.id, b.id],
            collision_type=pair.collision_type,
            emergence_score=emergence_score
        )
    
    def _merge_insights(self, a: CapsuleVector, b: CapsuleVector, pair: CollisionPair) -> str:
        """èåˆæ´è§"""
        parts = []
        
        # ä»ä¸¤ä¸ªèƒ¶å›Šæå–æ ¸å¿ƒ
        if pair.collision_type == "cross_domain":
            parts.append(f"é€šè¿‡è·¨åŸŸåˆ†æå‘ç°ï¼Œ{a.domain} ä¸ {b.domain} å­˜åœ¨æ·±å±‚å…³è”ï¼š")
            parts.append(f"â€¢ {a.domain}è§†è§’: {a.insight[:100]}...")
            parts.append(f"â€¢ {b.domain}è§†è§’: {b.insight[:100]}...")
            parts.append(f"å…±åŒå…³æ³¨: {', '.join(pair.shared_topics[:3])}")
        else:
            parts.append(f"çŸ¥è¯†èåˆåˆ†æï¼š")
            parts.append(f"â€¢ {a.title}: {a.insight[:150]}...")
            parts.append(f"â€¢ {b.title}: {b.insight[:150]}...")
        
        return "\n".join(parts)
    
    def _merge_evidence(self, a: CapsuleVector, b: CapsuleVector) -> List[str]:
        """åˆå¹¶è¯æ®"""
        evidence = []
        evidence.extend([f"[A] {e}" for e in a.evidence[:2]])
        evidence.extend([f"[B] {e}" for e in b.evidence[:2]])
        evidence.append(f"æ¥æº: {a.title[:30]} + {b.title[:30]}")
        return evidence[:5]
    
    def _merge_actions(self, a: CapsuleVector, b: CapsuleVector) -> List[str]:
        """åˆå¹¶è¡ŒåŠ¨å»ºè®®"""
        actions = []
        actions.extend(a.action_items[:2])
        actions.extend(b.action_items[:2])
        actions.append("åŸºäºèåˆåˆ†æåˆ¶å®šä¸‹ä¸€æ­¥è®¡åˆ’")
        return actions[:5]
    
    def _calculate_emergence_score(self, a: CapsuleVector, b: CapsuleVector, pair: CollisionPair) -> float:
        """è®¡ç®—æ¶Œç°è¯„åˆ†"""
        score = 0.0
        
        # è·¨åŸŸåŠ åˆ†
        if pair.collision_type == "cross_domain":
            score += 30
        elif pair.collision_type == "complementary":
            score += 20
        
        # ç›¸ä¼¼åº¦åŠ åˆ†
        score += pair.similarity * 30
        
        # å…±åŒè¯é¢˜åŠ åˆ†
        score += min(len(pair.shared_topics) * 10, 20)
        
        # è¯æ®å……åˆ†æ€§
        score += min((len(a.evidence) + len(b.evidence)) * 5, 20)
        
        return min(score, 100)
    
    def run_collision(self, save_to_hub: bool = False) -> List[EmergedCapsule]:
        """è¿è¡Œå®Œæ•´çš„ç¢°æ’æµç¨‹"""
        print(f"\n{'='*60}")
        print(f"ğŸ’¥ Capsule Collision Engine")
        print(f"{'='*60}\n")
        
        # 1. åŠ è½½èƒ¶å›Š
        count = self.load_capsules()
        if count == 0:
            print("âŒ æ²¡æœ‰èƒ¶å›Šå¯ç¢°æ’")
            return []
        
        # 2. æŸ¥æ‰¾ç¢°æ’å¯¹
        pairs = self.find_collision_pairs()
        
        # 3. æ‰§è¡Œç¢°æ’
        emerged = []
        print(f"\nğŸ§¬ æ‰§è¡Œç¢°æ’...")
        for i, pair in enumerate(pairs, 1):
            new_cap = self.collide(pair)
            if new_cap:
                emerged.append(new_cap)
                print(f"  [{i}] {new_cap.title[:45]} (è¯„åˆ†: {new_cap.emergence_score:.0f})")
        
        self.emerged_capsules = emerged
        
        # 4. ç»Ÿè®¡
        print(f"\nğŸ“Š ç¢°æ’ç»“æœ:")
        print(f"   ç¢°æ’å¯¹: {len(pairs)}")
        print(f"   æ¶Œç°èƒ¶å›Š: {len(emerged)}")
        print(f"   å¹³å‡è¯„åˆ†: {sum(e.emergence_score for e in emerged)/max(len(emerged),1):.1f}")
        
        if save_to_hub:
            self._save_to_capsulehub()
        
        return emerged
    
    def _save_to_capsulehub(self):
        """ä¿å­˜æ¶Œç°èƒ¶å›Šåˆ° CapsuleHub"""
        print(f"\nğŸ’¾ ä¿å­˜åˆ° CapsuleHub...")
        saved = 0
        
        for capsule in self.emerged_capsules:
            try:
                data = {
                    "title": capsule.title,
                    "domain": capsule.domain,
                    "topics": capsule.topics,
                    "insight": capsule.insight,
                    "evidence": capsule.evidence,
                    "action_items": capsule.action_items,
                    "authors": ["CapsuleCollisionEngine"],
                    "is_emergent": True,
                    "parent_capsules": capsule.parent_capsules
                }
                
                url = f"{self.capsulehub_url}/api/capsules"
                req = urllib.request.Request(
                    url,
                    data=json.dumps(data).encode(),
                    headers={"Content-Type": "application/json"},
                    method="POST"
                )
                
                with urllib.request.urlopen(req) as response:
                    saved += 1
                    print(f"  âœ… {capsule.title[:40]}")
            except Exception as e:
                print(f"  âŒ {capsule.title[:40]}: {e}")
        
        print(f"\nâœ… æˆåŠŸä¿å­˜ {saved} ä¸ªæ¶Œç°èƒ¶å›Šåˆ° CapsuleHub")
    
    def get_report(self) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        return {
            "total_capsules": len(self.capsules),
            "collision_pairs": len(self.find_collision_pairs()),
            "emerged_capsules": len(self.emerged_capsules),
            "average_score": sum(e.emergence_score for e in self.emerged_capsules)/max(len(self.emerged_capsules),1),
            "by_type": {
                pair.collision_type: len([e for e in self.emerged_capsules if e.collision_type == pair.collision_type])
                for pair in self.emerged_capsules
            }
        }


def main():
    """ä¸»å‡½æ•°"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸ’¥ Capsule Collision Engine - çŸ¥è¯†èƒ¶å›Šè‡ªæ¶Œç°ç³»ç»Ÿ               â•‘
â•‘                                                                      â•‘
â•‘  èƒ¶å›Šä¹‹é—´ç›´æ¥ç¢°æ’ï¼Œåœ¨è¯­ä¹‰ç©ºé—´ä¸­äº§ç”Ÿæ–°çš„çŸ¥è¯†ç«èŠ±ï¼                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    engine = CapsuleCollisionEngine()
    
    # è¿è¡Œç¢°æ’
    emerged = engine.run_collision(save_to_hub=False)
    
    # æ˜¾ç¤ºæ¶Œç°çš„èƒ¶å›Š
    if emerged:
        print(f"\nğŸŒŸ æ¶Œç°çš„æ–°çŸ¥è¯†:")
        for i, cap in enumerate(emerged[:5], 1):
            print(f"\n{i}. {cap.title}")
            print(f"   é¢†åŸŸ: {cap.domain}")
            print(f"   è¯„åˆ†: {cap.emergence_score:.0f}")
            print(f"   æ´è§: {cap.insight[:80]}...")
    
    return engine


if __name__ == "__main__":
    main()
